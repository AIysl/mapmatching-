{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare GPS data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Seattle GPS Trajectory\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>datatime</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47.667483</td>\n",
       "      <td>-122.107083</td>\n",
       "      <td>2009-01-17 20:27:37</td>\n",
       "      <td>1.232195e+09</td>\n",
       "      <td>POINT (-13592898.33520784 6020110.32713188)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.667500</td>\n",
       "      <td>-122.107067</td>\n",
       "      <td>2009-01-17 20:27:38</td>\n",
       "      <td>1.232195e+09</td>\n",
       "      <td>POINT (-13592896.48730429 6020113.074315307)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47.667500</td>\n",
       "      <td>-122.107067</td>\n",
       "      <td>2009-01-17 20:27:39</td>\n",
       "      <td>1.232195e+09</td>\n",
       "      <td>POINT (-13592896.48730429 6020113.074315307)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.667517</td>\n",
       "      <td>-122.107033</td>\n",
       "      <td>2009-01-17 20:27:40</td>\n",
       "      <td>1.232195e+09</td>\n",
       "      <td>POINT (-13592892.7692333 6020115.821499617)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47.667533</td>\n",
       "      <td>-122.106983</td>\n",
       "      <td>2009-01-17 20:27:41</td>\n",
       "      <td>1.232195e+09</td>\n",
       "      <td>POINT (-13592887.20325876 6020118.56703683)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lat         lon            datatime     timestamp  \\\n",
       "0  47.667483 -122.107083 2009-01-17 20:27:37  1.232195e+09   \n",
       "1  47.667500 -122.107067 2009-01-17 20:27:38  1.232195e+09   \n",
       "2  47.667500 -122.107067 2009-01-17 20:27:39  1.232195e+09   \n",
       "3  47.667517 -122.107033 2009-01-17 20:27:40  1.232195e+09   \n",
       "4  47.667533 -122.106983 2009-01-17 20:27:41  1.232195e+09   \n",
       "\n",
       "                                       geometry  \n",
       "0   POINT (-13592898.33520784 6020110.32713188)  \n",
       "1  POINT (-13592896.48730429 6020113.074315307)  \n",
       "2  POINT (-13592896.48730429 6020113.074315307)  \n",
       "3   POINT (-13592892.7692333 6020115.821499617)  \n",
       "4   POINT (-13592887.20325876 6020118.56703683)  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load GPS data\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "crs = {'init': 'epsg:4326'}\n",
    "to_crs = {'init': 'epsg:3395'}\n",
    "\n",
    "\n",
    "def load_gps_data_melbourne(file, crs, to_crs):\n",
    "    print('loading Melbourne GPS Trajectory')\n",
    "    gps_track = pd.read_csv(file, \n",
    "                            header=None, \n",
    "                            names=['timestamp', 'lat', 'lon'], \n",
    "                            skiprows=[0], \n",
    "                            delim_whitespace=True)\n",
    "    gps_track['geometry'] = gps_track.apply(lambda row: Point(row['lon'], row['lat']), axis=1)\n",
    "    gps_track['gps'] = gps_track['geometry']\n",
    "    gps_track = gpd.GeoDataFrame(gps_track, crs=crs)\n",
    "    gps_track.to_crs(to_crs, inplace=True)\n",
    "    return gps_track\n",
    "\n",
    "\n",
    "def load_GPS_data_Seattle(file, crs, to_crs):\n",
    "    print('loading Seattle GPS Trajectory')\n",
    "    gps_track = pd.read_csv(file,\n",
    "                            header=None,\n",
    "                            names=['Data(UTC)', 'Time(UTC)', 'lat', 'lon'],\n",
    "                            skiprows=[0],\n",
    "                            delim_whitespace=True)\n",
    "    # string to datatime\n",
    "    gps_track['datatime'] = gps_track.apply(\n",
    "        lambda row: datetime.strptime(row['Data(UTC)'] + ' ' + row['Time(UTC)'], '%d-%b-%Y %H:%M:%S'), axis=1)\n",
    "    gps_track.drop(['Data(UTC)', 'Time(UTC)'], axis=1, inplace=True)\n",
    "    # datatime to unix time\n",
    "    gps_track['timestamp'] = gps_track.apply(lambda row: time.mktime(row['datatime'].timetuple()), axis=1)\n",
    "    gps_track['geometry'] = gps_track.apply(lambda row: Point(row['lon'], row['lat']), axis=1)\n",
    "    gps_track = gpd.GeoDataFrame(gps_track, crs=crs)\n",
    "    gps_track.to_crs(to_crs, inplace=True)\n",
    "    return gps_track\n",
    "\n",
    "\n",
    "gps_track = load_GPS_data_Seattle('./data/Seattle/gps_data.txt', crs, to_crs)\n",
    "#gps_track = load_gps_data_melbourne('./data/Melbourne/gps_track.txt', crs, to_crs)\n",
    "gps_track.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load road network data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Seattle Road Network ...\n",
      "133460 130029\n",
      "--- 111.860000134 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapely.wkt\n",
    "from shapely.geometry import LineString, Point\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "## http://wikicode.wikidot.com/get-angle-of-line-between-two-points\n",
    "## angle between two points\n",
    "def calculate_bearing(pt1, pt2):\n",
    "    import math\n",
    "    x_diff = pt2.x - pt1.x\n",
    "    y_diff = pt2.y - pt1.y\n",
    "    bearing = math.degrees(math.atan2(y_diff, x_diff))\n",
    "    if bearing < 0:\n",
    "        return bearing + 360\n",
    "    else:\n",
    "        return bearing\n",
    "\n",
    "def heading_difference(A, B):\n",
    "    d = max(A,B)-min(A,B)\n",
    "    if d > 180:\n",
    "        d=360-d\n",
    "    return d\n",
    "\n",
    "\n",
    "def max_speed(road_type):\n",
    "    if road_type == 1:\n",
    "        return 100\n",
    "    elif road_type == 2:\n",
    "        return 60\n",
    "    elif road_type == 3:\n",
    "        return 50\n",
    "    elif road_type == 4:\n",
    "        return 50\n",
    "    elif road_type == 5:\n",
    "        return 80\n",
    "    elif road_type == 6:\n",
    "        return 30\n",
    "    else:\n",
    "        return 40\n",
    "    \n",
    "def load_road_network(filename, crs, to_crs):\n",
    "    print('loading Melbourne Road Network ...')\n",
    "    road = pd.read_csv(filename, \n",
    "                        header=None, \n",
    "                        names=['Edge_ID','from', 'from lon', 'from lat', \n",
    "                               'to', 'to lon', 'to lat',\n",
    "                               'length', 'road type', 'bearing'], \n",
    "                        skiprows=[0], \n",
    "                        sep=' ')\n",
    "    road['geometry'] = road.apply(lambda row: \n",
    "                                  LineString([(row['from lon'], row['from lat']), (row['to lon'], row['to lat'])]), axis=1)\n",
    "    road['max speed'] = road.apply(lambda row: max_speed(row['road type']), axis=1)\n",
    "    road['gps'] = road['geometry']\n",
    "    road = gpd.GeoDataFrame(road, crs=crs, geometry='geometry')\n",
    "    # coordinate transformation\n",
    "    road.to_crs(to_crs, inplace=True)\n",
    "    road['bbox'] = road.apply(lambda row: row['geometry'].bounds, axis=1)\n",
    "    road_graph = nx.from_pandas_edgelist(\n",
    "        pd.DataFrame(road, columns=('Edge_ID', 'from', 'to', 'gps', 'geometry', 'max speed', 'length', 'bbox')), \n",
    "                                     'from', \n",
    "                                     'to', \n",
    "                                     ['Edge_ID', 'max speed', 'geometry', 'length'], \n",
    "                                     create_using=nx.MultiDiGraph())\n",
    "    return road, road_graph\n",
    "\n",
    "def update_nodes_ids(road):\n",
    "    #nodes_list = []\n",
    "    nodes_dict = {}\n",
    "    for row_index, row in road.iterrows():        \n",
    "        start_point = row['geometry'].coords[0]\n",
    "        start_node_id = row['From_Node_ID']\n",
    "        if nodes_dict.has_key(start_node_id):\n",
    "            if nodes_dict[start_node_id][0] != start_point:\n",
    "                print(start_node_id, nodes_dict[start_node_id], (start_point, row_index))\n",
    "        else:\n",
    "            nodes_dict[start_node_id] = (start_point, row_index)\n",
    "        end_point = row['geometry'].coords[-1]\n",
    "        end_node_id = row['To_Node_ID']\n",
    "        if nodes_dict.has_key(end_node_id):\n",
    "            if nodes_dict[end_node_id][0] != end_point:\n",
    "                print(end_node_id, nodes_dict[end_node_id], (end_point, row_index))\n",
    "        else:\n",
    "            nodes_dict[end_node_id] = (end_point, row_index)\n",
    "    same_nodes=[]\n",
    "    point_id_dict = {}\n",
    "    road_values = road.values\n",
    "    for key, value in nodes_dict.items():\n",
    "        if point_id_dict.has_key(value[0]):\n",
    "            node_id = point_id_dict[value[0]]\n",
    "            #if (road.iloc[value[1]]['From_Node_ID'] == key) or (road.iloc[value[1]]['To_Node_ID'] == key):\n",
    "            #    same_nodes.append([value[1], key, node_id])\n",
    "            from_node_id = road.iloc[value[1]]['From_Node_ID']\n",
    "            to_node_id = road.iloc[value[1]]['To_Node_ID']\n",
    "            if from_node_id == key:                   \n",
    "                #road.iloc[same_nodes[i][0]]['From_Node_ID'] = same_nodes[i][2]\n",
    "                road_values[value[1]][1] = node_id\n",
    "            elif to_node_id == key:           \n",
    "                #road.iloc[same_nodes[i][0]]['To_Node_ID'] = same_nodes[i][2]\n",
    "                road_values[value[1]][2] = node_id\n",
    "            else:\n",
    "                print('Node %d is not in edge %d.'%(key, value[1]))\n",
    "            #same_nodes.append([value[1], key, node_id])\n",
    "        else:\n",
    "            point_id_dict[value[0]] = key\n",
    "    \n",
    "    print len(nodes_dict), len(point_id_dict)\n",
    "    column_names = ['Edge_ID', 'From_Node_ID', 'To_Node_ID', 'Two_Way', 'Speed(m/s)', 'Vertex_Count', 'geometry']\n",
    "    return pd.DataFrame(road_values, columns=column_names )\n",
    "    \n",
    "    \n",
    "\n",
    "def load_road_network_seattle(filename, crs, to_crs):\n",
    "    \"\"\"\n",
    "    prepare Seattle road network data\n",
    "    :param filename:\n",
    "    :param crs:\n",
    "    :param to_crs\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    print('loading Seattle Road Network ...')\n",
    "    column_names = ['Edge_ID', 'From_Node_ID', 'To_Node_ID', 'Two_Way', 'Speed(m/s)', 'Vertex_Count', 'geometry']\n",
    "    road = pd.read_csv(filename, header=None, names=column_names, skiprows=[0], sep='\\t')\n",
    "    road['geometry'] = road.apply(lambda row: shapely.wkt.loads(row['geometry']), axis=1)    \n",
    "    # update node ids\n",
    "    road = update_nodes_ids(road)\n",
    "    #print road.values.shape, updated_road.values.shape\n",
    "    road = gpd.GeoDataFrame(road, crs=crs, geometry='geometry')\n",
    "    road.to_crs(to_crs, inplace=True)\n",
    "    road['length'] = road.apply(lambda row: row['geometry'].length, axis=1)\n",
    "    road['bbox'] = road.apply(lambda row: row['geometry'].bounds, axis=1)\n",
    "    #print len(road)\n",
    "    direct_edges_list = []\n",
    "    idx = 0\n",
    "    for row_index, row in road.iterrows():\n",
    "        direct_edges_list.append([idx, row['Edge_ID'], row['From_Node_ID'], row['To_Node_ID'],\n",
    "                                  row['Speed(m/s)'], row['geometry'], row['length'], row['bbox'], 1])\n",
    "        idx = idx+1\n",
    "        if 1 == row['Two_Way']:\n",
    "            direct_edges_list.append([idx, row['Edge_ID'], row['To_Node_ID'], row['From_Node_ID'],\n",
    "                                      row['Speed(m/s)'], LineString(list(row['geometry'].coords)[::-1]),\n",
    "                                     row['length'], row['bbox'], 0])\n",
    "            idx = idx+1\n",
    "    edges = pd.DataFrame(\n",
    "        direct_edges_list,\n",
    "        columns=('Edge_ID', 'osm_edge_id', 'from', 'to', 'max speed', 'geometry', 'length', 'bbox', 'from_to'))\n",
    "    edges['bearing'] = \\\n",
    "        edges.apply(lambda edge:\n",
    "                    calculate_bearing(Point(edge['geometry'].coords[0]), Point(edge['geometry'].coords[1])), axis=1)\n",
    "    road_graph = nx.from_pandas_edgelist(edges,\n",
    "                                         'from',\n",
    "                                         'to',\n",
    "                                         ['Edge_ID', 'max speed', 'geometry', 'length'],\n",
    "                                         create_using=nx.MultiDiGraph())\n",
    "    # print len(edges)\n",
    "    # print len(direct_edges_list)\n",
    "    return road_graph, gpd.GeoDataFrame(edges, crs=to_crs, geometry='geometry'), \n",
    "\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "road_graph, edges_gpd = load_road_network_seattle('./data/Seattle/road_network.txt', crs, to_crs)\n",
    "# edges_gpd, road_graph = load_road_network('./data/Melbourne/complete-osm-map/streets.txt', crs, to_crs)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trajectory segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBR Calculation\n",
    "from shapely.geometry import Point\n",
    "def obr(track, d_error, min_num_points):\n",
    "    # create initial rectangle\n",
    "    clusters = []\n",
    "    outliers = []\n",
    "    removed = []\n",
    "    anchor = [False for i in range(len(track))]\n",
    "    cluster = [0,1]    \n",
    "    c1 = track.iloc[cluster[0]]['geometry'].buffer(d_error).exterior\n",
    "    for i in range(2, len(track)):        \n",
    "        c2 = track.iloc[i]['geometry'].buffer(d_error).exterior\n",
    "        mbr_new = c1.union(c2).minimum_rotated_rectangle\n",
    "        possible_outliers = []\n",
    "        for item in cluster[1:]:\n",
    "            if not mbr_new.contains(track.iloc[item]['geometry']):\n",
    "                anchor[item] = True\n",
    "                possible_outliers.append(item)\n",
    "        # remove outliers\n",
    "        j = 0\n",
    "        while j < len(possible_outliers):\n",
    "            if anchor[possible_outliers[j]-1] == False and anchor[possible_outliers[j]+1] ==False:\n",
    "                outliers.append(possible_outliers[j])\n",
    "                cluster.remove(possible_outliers[j])\n",
    "                possible_outliers.remove(possible_outliers[j])                \n",
    "            else:\n",
    "                j=j+1\n",
    "        if len(possible_outliers) > 0:            \n",
    "            # divide current cluster into two parts          \n",
    "            ind = cluster.index(possible_outliers[-1])\n",
    "            first_part = [cluster[k] for k in range(ind+1)]\n",
    "            second_part = [cluster[k] for k in range(ind,len(cluster))]\n",
    "            #print possible_outliers\n",
    "            #print first_part\n",
    "            #print second_part            \n",
    "            #print '-----'\n",
    "            if len(first_part) > min_num_points:\n",
    "                clusters.append(first_part)\n",
    "            else:\n",
    "                removed.append(first_part)\n",
    "            cluster = second_part\n",
    "            cluster.append(i)\n",
    "            c1 = track.iloc[cluster[0]]['geometry'].buffer(d_error).exterior \n",
    "        else:\n",
    "            cluster.append(i)\n",
    "    if len(cluster) > min_num_points:\n",
    "        clusters.append(cluster)     \n",
    "    return clusters, outliers, removed       \n",
    "\n",
    "\n",
    "#d_error = 10\n",
    "#clusters, outliers, removed = obr(gps_track, d_error, 2)\n",
    "#len(clusters), len(outliers), len(removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_heading_difference(edges_gpd, edge_id, mbr, mbr_heading):\n",
    "    import shapely\n",
    "    edge_bearing = edges_gpd.iloc[edge_id]['bearing']\n",
    "    a = edges_gpd.iloc[edge_id]['geometry'].difference(mbr)\n",
    "    if isinstance(a, shapely.geometry.multilinestring.MultiLineString):\n",
    "        p1 = shapely.geometry.Point(list(a.geoms)[0].coords[-1])\n",
    "        p2 = shapely.geometry.Point(list(a.geoms)[1].coords[0])\n",
    "        edge_bearing = calculate_bearing(p1, p2)\n",
    "    elif isinstance(a, shapely.geometry.LineString):\n",
    "        if a.coords[0] == edges_gpd.iloc[edge_id]['geometry'].coords[0] and a.coords[-1] == edges_gpd.iloc[edge_id]['geometry'].coords[-1]:\n",
    "            pass\n",
    "        elif a.coords[0] == edges_gpd.iloc[edge_id]['geometry'].coords[0]:\n",
    "            p1 = shapely.geometry.Point(a.coords[-1])\n",
    "            p2 = shapely.geometry.Point(edges_gpd.iloc[edge_id]['geometry'].coords[-1])\n",
    "            edge_bearing = calculate_bearing(p1, p2)\n",
    "        else:\n",
    "            p1 = shapely.geometry.Point(edges_gpd.iloc[edge_id]['geometry'].coords[0])\n",
    "            p2 = shapely.geometry.Point(a.coords[0])\n",
    "            edge_bearing = calculate_bearing(p1, p2)\n",
    "    else:\n",
    "        if a.is_empty:\n",
    "            pass\n",
    "        else:\n",
    "            print type(a)\n",
    "    diff = heading_difference(mbr_heading, edge_bearing)\n",
    "    return diff\n",
    "\n",
    "\n",
    "def filter_edges(mbr, mbr_heading, edges_gpd, edges, a_error):    \n",
    "    flag = [True for i in range(len(edges))]\n",
    "    count = 0\n",
    "    for i in range(len(edges)):\n",
    "        diff = calculate_heading_difference(edges_gpd, edges[i], mbr, mbr_heading)\n",
    "        if diff > a_error:\n",
    "            flag[i] = False\n",
    "            count = count+1\n",
    "    new_edges = []\n",
    "    for i in range(len(flag)):\n",
    "        if flag[i]:\n",
    "            new_edges.append(edges[i])\n",
    "    return new_edges\n",
    "\n",
    "\n",
    "def filter_routes(routes):\n",
    "    flag = [True for i in range(len(routes))]\n",
    "    for i in range(len(routes)-1):\n",
    "        for j in range(i+1,len(routes)):\n",
    "            if flag[i] and flag[j]:\n",
    "                if len(routes[i]) < len(routes[j]):\n",
    "                    if (routes[i][0] in routes[j]) and (routes[i][-1] in routes[j]):\n",
    "                        ind_1 = routes[j].index(routes[i][0])\n",
    "                        ind_2 = routes[j].index(routes[i][-1])\n",
    "                        if ind_2-ind_1+1 == len(routes[i]):\n",
    "                            flag[i] = False\n",
    "                            break\n",
    "                else:\n",
    "                    if (routes[j][0] in routes[i]) and (routes[j][-1] in routes[i]):\n",
    "                        ind_1 = routes[i].index(routes[j][0])\n",
    "                        ind_2 = routes[i].index(routes[j][-1])\n",
    "                        if ind_2-ind_1+1 == len(routes[j]):\n",
    "                            flag[j] = False\n",
    "    new_routes=[]\n",
    "    for i in range(len(flag)):\n",
    "        if flag[i]: \n",
    "            new_routes.append(routes[i])\n",
    "    return new_routes\n",
    "\n",
    "\n",
    "def filter_duplicate_routes(routes):\n",
    "    flag = [True for i in range(len(routes))]\n",
    "    for i in range(len(routes)-1):\n",
    "        for j in range(i+1,len(routes)):\n",
    "            if flag[i] or flag[j]:\n",
    "                if len(routes[i]) < len(routes[j]):\n",
    "                    if (routes[i][0] in routes[j]) and (routes[i][-1] in routes[j]):\n",
    "                        ind_1 = routes[j].index(routes[i][0])\n",
    "                        ind_2 = routes[j].index(routes[i][-1])\n",
    "                        if ind_2-ind_1+1 == len(routes[i]):\n",
    "                            flag[j] = False\n",
    "                else:\n",
    "                    if (routes[j][0] in routes[i]) and (routes[j][-1] in routes[i]):\n",
    "                        ind_1 = routes[i].index(routes[j][0])\n",
    "                        ind_2 = routes[i].index(routes[j][-1])\n",
    "                        if ind_2-ind_1+1 == len(routes[j]):\n",
    "                            flag[i] = False\n",
    "    new_routes=[]\n",
    "    for i in range(len(flag)):\n",
    "        if flag[i]: \n",
    "            new_routes.append(routes[i])\n",
    "    return new_routes\n",
    "\n",
    "\n",
    "def calculate_shortest_path(road_graph, edges_gpd, start_edge_id, end_edge_id):\n",
    "    route = []\n",
    "    if start_edge_id == end_edge_id:\n",
    "        route.append(start_edge_id)\n",
    "    elif edges_gpd.iloc[start_edge_id]['to'] == edges_gpd.iloc[end_edge_id]['from']:\n",
    "        route.append(start_edge_id)\n",
    "        route.append(end_edge_id)\n",
    "    else:\n",
    "        source = edges_gpd.iloc[start_edge_id]['to']\n",
    "        target = edges_gpd.iloc[end_edge_id]['from']\n",
    "        try:\n",
    "            #net_distance = nx.shortest_path_length(road_graph, source, target, weight='length')\n",
    "            sp = nx.shortest_path(road_graph, source, target, weight='length')\n",
    "        except Exception as err:\n",
    "            print err\n",
    "            #net_distance = 3*eu_distance\n",
    "        else:    \n",
    "            route.append(start_edge_id)\n",
    "            for i in range(1, len(sp)):\n",
    "                route.append(road_graph[sp[i-1]][sp[i]][0]['Edge_ID'])\n",
    "            route.append(end_edge_id)\n",
    "    return route\n",
    "\n",
    "\n",
    "def save_to_file_candidate_routes(filename, candidates):\n",
    "    with open(filename, 'w') as fwritter:\n",
    "        for i in range(len(candidates)):\n",
    "            fwritter.write('%d:\\n' % i)\n",
    "            candidate_routes = candidates.iloc[i]['candidate_routes']\n",
    "            # print candidate_routes\n",
    "            obs_prob = candidates.iloc[i]['obs_prob']\n",
    "            # print obs_prob\n",
    "            for j in range(len(candidate_routes)):\n",
    "                for edge_id in candidate_routes[j]:\n",
    "                    fwritter.write('%d, ' % edge_id)\n",
    "                fwritter.write('[%f]' % obs_prob[j])\n",
    "                fwritter.write('\\n')\n",
    "            fwritter.write('\\n')\n",
    "\n",
    "            \n",
    "def save_to_file_transit_routes(filename, candidates):\n",
    "    with open(filename, 'w') as fWriter:\n",
    "        for idx in range(1, len(candidates)):\n",
    "            fWriter.write('%d to %d:\\n' % (candidates.iloc[idx]['pre_cluster'], idx))\n",
    "            possible_paths = candidates.iloc[idx]['tran_routes']\n",
    "            tran_prob = candidates.iloc[idx]['tran_prob']\n",
    "            distances = candidates.iloc[idx]['distances']\n",
    "            for i in range(len(possible_paths)):                \n",
    "                for j in range(len(possible_paths[i])):                    \n",
    "                    #for k in range(len(possible_paths[i][j])):                    \n",
    "                    for edge_id in possible_paths[i][j]:\n",
    "                        fWriter.write('%d, ' % edge_id)\n",
    "                    fWriter.write('[%f, %f, %f]\\n' % (distances[i][j][0], distances[i][j][1], tran_prob[i][j]))\n",
    "            fWriter.write('\\n') \n",
    "            \n",
    "            \n",
    "def map_osm_edge_id(edges_gpd, opt_route):\n",
    "    opt_route_osm_edge_id = []\n",
    "    for edge_id in opt_route:\n",
    "        opt_route_osm_edge_id.append((edges_gpd.iloc[edge_id]['osm_edge_id'],edges_gpd.iloc[edge_id]['from_to']))\n",
    "    return opt_route_osm_edge_id\n",
    "\n",
    "\n",
    "def save_to_file_matching_result_seattle(filename, opt_route):\n",
    "    with open(filename, 'w') as fwritter:\n",
    "        fwritter.write('%d\\n' % len(opt_route))\n",
    "        for i in range(len(opt_route)):\n",
    "            fwritter.write('%d\\t%d\\n' % (opt_route[i][0], opt_route[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query candidate edges and routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_edges_by_point_range(edges_gpd, point, diameter):\n",
    "    from shapely.ops import nearest_points\n",
    "    edge_ids = list(edges_gpd.sindex.intersection(point.buffer(diameter).exterior.bounds, objects='raw'))\n",
    "    edge_id_list = []\n",
    "    for edge_id in edge_ids:\n",
    "        edge = edges_gpd.iloc[edge_id]\n",
    "        results = nearest_points(point, edge['geometry'])\n",
    "        d = point.distance(results[1])\n",
    "        if d <= diameter:\n",
    "            edge_id_list.append(edge['Edge_ID'])       \n",
    "    return edge_id_list\n",
    "\n",
    "\n",
    "def calculate_observation_probability(edges_gpd, routes, mbr, mbr_heading):\n",
    "    import shapely\n",
    "    obs_prob = []\n",
    "    for route in routes:\n",
    "        diff_sum = 0.0\n",
    "        for edge_id in route:\n",
    "            diff = calculate_heading_difference(edges_gpd, edge_id, mbr, mbr_heading)\n",
    "            diff_sum = diff_sum + diff\n",
    "        p = 1 - diff_sum/(180*len(route))\n",
    "        obs_prob.append(p)\n",
    "    return obs_prob\n",
    "\n",
    "\n",
    "def query_candidate_routes_by_cluster(road_graph, edges_gpd, gps_track, clusters, d_error, a_error):\n",
    "    results = []\n",
    "    for i in range(len(clusters)):\n",
    "        start_p = gps_track.iloc[clusters[i][0]]['geometry']\n",
    "        end_p = gps_track.iloc[clusters[i][-1]]['geometry']              \n",
    "        c1 = start_p.buffer(d_error).exterior\n",
    "        c2 = end_p.buffer(d_error).exterior\n",
    "        mbr = c1.union(c2).minimum_rotated_rectangle\n",
    "        mbr_heading = calculate_bearing(start_p, end_p)           \n",
    "        # search for candidate edges\n",
    "        start_edges = query_edges_by_point_range(edges_gpd, start_p, d_error)\n",
    "        end_edges = query_edges_by_point_range(edges_gpd, end_p, d_error)\n",
    "        # filtering candidate edges\n",
    "        start_edges = filter_edges(mbr, mbr_heading, edges_gpd, start_edges, a_error)\n",
    "        end_edges = filter_edges(mbr, mbr_heading, edges_gpd, end_edges, a_error)        \n",
    "        # construct candidate routes\n",
    "        routes=[]\n",
    "        for start in start_edges:\n",
    "            for end in end_edges:\n",
    "                route = calculate_shortest_path(road_graph, edges_gpd, start, end)\n",
    "                if route:\n",
    "                    routes.append(route)\n",
    "        \n",
    "        if not routes:\n",
    "            if start_edges:\n",
    "                for edge_id in start_edges: routes.append([edge_id])\n",
    "            if end_edges:\n",
    "                for edge_id in end_edges: routes.append([edge_id])\n",
    "        \n",
    "        if routes:\n",
    "            if i < len(clusters)-1:\n",
    "                routes = filter_duplicate_routes(routes)\n",
    "            #else:\n",
    "            #    routes = filter_routes(routes)\n",
    "        else:\n",
    "            #print('cluster %d does not have candidate routes!' % i)\n",
    "            #print start_edges, end_edges\n",
    "            pass\n",
    "        obs_prob = calculate_observation_probability(edges_gpd, routes, mbr, mbr_heading)\n",
    "        results.append([mbr, mbr_heading, (start_edges, end_edges), routes, obs_prob])\n",
    "        column_names = ['mbr', 'mbr_heading', 'candidate_edges', 'candidate_routes', 'obs_prob']\n",
    "    return pd.DataFrame(results, columns=column_names)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_transit_route(road_graph, edges_gpd, gps_track, cluster, next_cluster, route, next_route):    \n",
    "    new_route=[]\n",
    "    net_distance = 0\n",
    "    if (next_route[0] in route):\n",
    "        ind1 = route.index(next_route[0])\n",
    "        if len(route)-ind1 <= len(next_route):\n",
    "            if route[ind1:] == next_route[0:len(route)-ind1]:\n",
    "                new_route=[edge_id for edge_id in route]\n",
    "                new_route.extend(next_route[len(route)-ind1:])    \n",
    "                #print route, next_route, new_route    \n",
    "    if not new_route:\n",
    "        sp = calculate_shortest_path(road_graph, edges_gpd, route[-1], next_route[0])\n",
    "        if sp:\n",
    "            new_route.extend(route)\n",
    "            new_route.extend(sp[1:])\n",
    "            new_route.extend(next_route[1:])      \n",
    "    # calculate network distance\n",
    "    if new_route:\n",
    "        for i in range(len(new_route)-1):\n",
    "            net_distance = net_distance + edges_gpd.iloc[new_route[i]]['length']\n",
    "        net_distance = net_distance + edges_gpd.iloc[new_route[-1]]['geometry'].project(gps_track.iloc[next_cluster[-1]]['geometry'])\n",
    "        net_distance = net_distance - edges_gpd.iloc[new_route[0]]['geometry'].project(gps_track.iloc[cluster[0]]['geometry'])            \n",
    "    return net_distance, new_route\n",
    "\n",
    "def calculate_transit_routes(road_graph, edges_gpd, gps_track, clusters, candidates, ind_pre, ind):\n",
    "    # calculate euclidean distance\n",
    "    p1 = gps_track.iloc[clusters[ind_pre][0]]['geometry']\n",
    "    p2 = gps_track.iloc[clusters[ind_pre][-1]]['geometry']\n",
    "    eu_distance = p1.distance(p2)\n",
    "    p3 = gps_track.iloc[clusters[ind][0]]['geometry']\n",
    "    eu_distance = eu_distance + p2.distance(p3)\n",
    "    p4 = gps_track.iloc[clusters[ind][-1]]['geometry']\n",
    "    eu_distance = eu_distance + p3.distance(p4)\n",
    "    routes = []\n",
    "    tran_prob = []\n",
    "    distances = []\n",
    "    max_prob = 0\n",
    "    for r1 in candidates.iloc[ind]['candidate_routes']:\n",
    "        temp_routes = []\n",
    "        temp_tran_prob = []\n",
    "        temp_distances = []\n",
    "        for r2 in candidates.iloc[ind_pre]['candidate_routes']:            \n",
    "            net_distance, new_route =  calculate_transit_route(road_graph,\n",
    "                                                        edges_gpd, \n",
    "                                                        gps_track, \n",
    "                                                        clusters[ind_pre], \n",
    "                                                        clusters[ind],\n",
    "                                                        r2,\n",
    "                                                        r1)\n",
    "            if (not new_route) and (net_distance == 0):\n",
    "                t_p = 0.0000001\n",
    "            elif net_distance > 2*eu_distance:\n",
    "                t_p = 0.0000001\n",
    "            else:\n",
    "                t_p = 1-abs(eu_distance-net_distance)/eu_distance\n",
    "            if t_p > max_prob:\n",
    "                max_prob = t_p\n",
    "            temp_routes.append(new_route)\n",
    "            temp_tran_prob.append(t_p)\n",
    "            temp_distances.append((eu_distance, net_distance))\n",
    "        routes.append(temp_routes)\n",
    "        tran_prob.append(temp_tran_prob)\n",
    "        distances.append(temp_distances)  \n",
    "    return routes, tran_prob, distances, max_prob\n",
    "\n",
    "\n",
    "def calculate_transit_routes_by_cluster(road_graph, edges_gpd, gps_track, clusters, candidates):\n",
    "    pre_cluster_ids = [-1]    \n",
    "    routes_list = [[]]\n",
    "    tran_prob_list = [[]]  \n",
    "    distances_list = [[]]\n",
    "    i_pre = 0\n",
    "    i = 1\n",
    "    while i < len(candidates):   \n",
    "        while not candidates.iloc[i]['candidate_routes']:\n",
    "            pre_cluster_ids.append(-1)\n",
    "            routes_list.append([])\n",
    "            tran_prob_list.append([])\n",
    "            distances_list.append([])\n",
    "            i = i+1\n",
    "            if i >= len(candidates):\n",
    "                i_pre = -1\n",
    "                break\n",
    "            \n",
    "        while i_pre >= 0:\n",
    "            if not candidates.iloc[i_pre]['candidate_routes']:\n",
    "                i_pre = i_pre-1\n",
    "            else:\n",
    "                break\n",
    "        if i_pre >= 0:\n",
    "            routes, tran_prob, distances, max_prob = calculate_transit_routes(road_graph, \n",
    "                                                                              edges_gpd, \n",
    "                                                                              gps_track, \n",
    "                                                                              clusters, \n",
    "                                                                              candidates, \n",
    "                                                                              i_pre, \n",
    "                                                                              i)\n",
    "       \n",
    "            if max_prob < 0.001: \n",
    "                #print distances\n",
    "                pre_cluster_ids.append(-1)\n",
    "                routes_list.append([])\n",
    "                tran_prob_list.append([])\n",
    "                distances_list.append([])\n",
    "            else:\n",
    "                pre_cluster_ids.append(i_pre)\n",
    "                routes_list.append(routes)\n",
    "                tran_prob_list.append(tran_prob)\n",
    "                distances_list.append(distances)\n",
    "            i_pre = i\n",
    "            i = i+1\n",
    "        else:\n",
    "            if i < len(candidates):\n",
    "                pre_cluster_ids.append(-1)\n",
    "                routes_list.append([])\n",
    "                tran_prob_list.append([])\n",
    "                distances_list.append([])\n",
    "                i_pre = i\n",
    "                i = i+1\n",
    "    print len(candidates), len(pre_cluster_ids), len(routes_list), len(tran_prob_list), len(distances_list)\n",
    "    candidates['pre_cluster'] = pre_cluster_ids\n",
    "    candidates['tran_routes'] = routes_list\n",
    "    candidates['tran_prob'] = tran_prob_list\n",
    "    candidates['distances'] = distances_list\n",
    "        \n",
    "    #return f, pre, possible_paths,tran_possibilities, final_cluster_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
